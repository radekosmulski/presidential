{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talk like the President, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I build up towards a simple char RNN architecture using the [fastai library](https://github.com/fastai/).\n",
    "\n",
    "The code is taken nearly line for line from [Lesson 6](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb) of the FastAI Part 1 v2 course. The diagrams come from the course videos.\n",
    "\n",
    "Jeremy provides a great overview of each of the architectures in the [lecture 6 video](https://youtu.be/sHcLkfRrgoQ?t=1h12m40s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dir if doesn't exist\n",
    "!mkdir -p data\n",
    "\n",
    "# Download and unzip corpus of speeches\n",
    "!wget 'http://www.thegrammarlab.com/?wpdmpro=corpus-of-presidential-speeches&wpdmdl=595' -O \"data/corpus.zip\"\n",
    "!unzip data/corpus.zip -d data/\n",
    "\n",
    "# Data from:\n",
    "#   Brown, D. W. (2016) Corpus of Presidential Speeches. Retrieved from http://www.thegrammarlab.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data taken from:\n",
    "#   Brown, D. W. (2016) Corpus of Presidential Speeches. Retrieved from http://www.thegrammarlab.com\n",
    "get_data('http://www.thegrammarlab.com/?wpdmpro=corpus-of-presidential-speeches&wpdmdl=595', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = ' '.join(preprocess_speech(file) for file in glob('data/Corpus of Presential Speeches/obama/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027441"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just over 1 mln chars! This should be perfect for our purposes!\n",
    "\n",
    "Let's start with creating a vocabulary of all the chars that are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 74\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(speeches)))\n",
    "vocab_size = len(chars)\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !\"$\\',-./0123456789:;>?ABCDEFGHIJKLMNOPQRSTUVWYZabcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to easily go from char to its index in the vocabulary and back. Let's use dictionaries for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: idx for idx, c in enumerate(chars)}\n",
    "idx2char = {idx: c for idx, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the speeches to representation as list of corresponding indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [char2idx[char] for char in speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 65, 7, 0, 41, 63, 52, 48, 58, 52, 65]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Speaker'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx2char[idx] for idx in idxs[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model - simple FC NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model will be very simple - we will use three chars to predict the fourth char. In order to do so, we embed each char using a rank 1 tensor of length 42. We concatenate the embeddings together and we slap a fully connected layer on top.\n",
    "\n",
    "It is a simple architecture that I wanted to try before we move onto RNNs!\n",
    "\n",
    "<img src='images/basic_nn.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fac = 42 # number of latent factors, embedding length\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_fac = n_fac\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # fully connected layer\n",
    "        self.l_in = nn.Linear(n_fac * 3, n_hidden)\n",
    "\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        inp = torch.cat([self.e(c1), self.e(c2), self.e(c3)], dim=1)\n",
    "        h = F.relu(self.l_in(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = idxs[0:-cs]\n",
    "c2_dat = idxs[1:-cs+1]\n",
    "c3_dat = idxs[2:-cs+2]\n",
    "c4_dat = idxs[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually inspecting whether the above worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', '.', ' ', 'T', 'h', 'a', 'n', 'k', ' ', 'y']\n",
      "['.', ' ', 'T', 'h', 'a', 'n', 'k', ' ', 'y', 'o']\n",
      "[' ', 'T', 'h', 'a', 'n', 'k', ' ', 'y', 'o', 'u']\n",
      "['T', 'h', 'a', 'n', 'k', ' ', 'y', 'o', 'u', '.']\n"
     ]
    }
   ],
   "source": [
    "print(list(idx2char[idx] for idx in c1_dat[-10:]))\n",
    "print(list(idx2char[idx] for idx in c2_dat[-10:]))\n",
    "print(list(idx2char[idx] for idx in c3_dat[-10:]))\n",
    "print(list(idx2char[idx] for idx in c4_dat[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)\n",
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1027438,), (1027438,), (1027438,), (1027438,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, x2.shape, x3.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our dataset from tese four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one line allows me to run my models on a subset of data while I work on this notebook\n",
    "# md = ColumnarModelData.from_arrays('.', [-20_000], np.stack([x1,x2,x3], axis=1)[:200_000, :], y[:200_000], bs=2**9)\n",
    "\n",
    "md = ColumnarModelData.from_arrays('.', [-100_000], np.stack([x1,x2,x3], axis=1), y, bs=2**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FCModel(vocab_size, n_fac, n_hidden).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5801c6e0594aaba94521dd8b621054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.61072  1.07665]                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9753a67d634c74ad222cbb57e4b0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.51321  1.00247]                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 1, opt, F.nll_loss)\n",
    "set_lrs(opt, 1e-3)\n",
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our model learned anything useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char2idx[c] for c in inp]))\n",
    "    p = m(*VV(idxs)).exp()\n",
    "    r = torch.multinomial(p, 1)\n",
    "    return idx2char[r.data[0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to produce something a bit longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goods, forman like are. And his now. I'm conomy belim 169000 sign-pers on here, decisiance is in studer of his ting ours America's who we can rultions in you lart gat was cal wanted forth be are strusine\n"
     ]
    }
   ],
   "source": [
    "text = 'Goo'\n",
    "for i in range(200): text += get_next(text[-3:])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this does sound like a president, but not the one whose manner of speech we are trying to emulate here. Let's try a slightly more complex architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char3Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, I am not sure if this is an RNN. It looks to me like an unrolled RNN but maybe it is missing something that it needs to be called an unrolled RNN. Either way, this is just semantics and we are very close to having a 'vanilla' RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/3char.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        # We are now feeding in chars one at a time! The input dimension of the first linear layer\n",
    "        # is (1, 42) vs the (1, 3 * 42) we used earlier.\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()).cuda()) # initiating our hidden state to all zeros\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560459e66d1a4078ab50463bd66e7bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.84013  3.70968]                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202d0cc16c8043f5994db258a29a7a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.60283  2.86376]                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 1, opt, F.nll_loss)\n",
    "set_lrs(opt, 1e-3)\n",
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our two tests to see if it learned anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gooteched to there hous crease bazensudenting an hado, will should if to cut distcover progle. But sumen I stant this thances more hown is in of to beliremocrate if hoperman if American't it's seears, re\n"
     ]
    }
   ],
   "source": [
    "text = 'Goo'\n",
    "for i in range(200): text += get_next(text[-3:])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to change our Char3Model into a 'real' RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharLoopModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/simple_RNN.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=8 # our model will generate predictions based on it seeing this many chars \n",
    "\n",
    "c_in_dat = [[idxs[i+j] for i in range(cs)] for j in range(len(idxs)-cs-1)]\n",
    "c_out_dat = [idxs[j+cs] for j in range(len(idxs)-cs-1)]\n",
    "\n",
    "xs = np.stack(c_in_dat, axis=0)\n",
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1027432, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 65, 7, 0, 41, 63, 52, 48],\n",
       " [65, 7, 0, 41, 63, 52, 48, 58],\n",
       " [7, 0, 41, 63, 52, 48, 58, 52],\n",
       " [0, 41, 63, 52, 48, 58, 52, 65],\n",
       " [41, 63, 52, 48, 58, 52, 65, 5],\n",
       " [63, 52, 48, 58, 52, 65, 5, 0],\n",
       " [52, 48, 58, 52, 65, 5, 0, 35],\n",
       " [48, 58, 52, 65, 5, 0, 35, 65]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[idx for idx in row] for row in xs[:8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M', 'r', '.', ' ', 'S', 'p', 'e', 'a'],\n",
       " ['r', '.', ' ', 'S', 'p', 'e', 'a', 'k'],\n",
       " ['.', ' ', 'S', 'p', 'e', 'a', 'k', 'e'],\n",
       " [' ', 'S', 'p', 'e', 'a', 'k', 'e', 'r'],\n",
       " ['S', 'p', 'e', 'a', 'k', 'e', 'r', ','],\n",
       " ['p', 'e', 'a', 'k', 'e', 'r', ',', ' '],\n",
       " ['e', 'a', 'k', 'e', 'r', ',', ' ', 'M'],\n",
       " ['a', 'k', 'e', 'r', ',', ' ', 'M', 'r']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[idx2char[idx] for idx in row] for row in xs[:cs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one line allows me to run my models on a subset of data while I work on this notebook\n",
    "# md = ColumnarModelData.from_arrays('.', [-20_000], xs[:200_000, :], y[:200_000], bs=2**9)\n",
    "\n",
    "md = ColumnarModelData.from_arrays('.', [-100_000], xs, y, bs=2**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c80f2e18ad4f8d8faf618cdd0d6e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.85732  4.13745]                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f343bc583e644448e213d1773018f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.54626  4.06182]                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 1, opt, F.nll_loss)\n",
    "set_lrs(opt, 1e-3)\n",
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Good mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good mould Afghanistant so not our inear ive or his know than is indurtment that of his that a businen doday be the for thirled withinefeumple, - Now, America. And eachorde that and the part their part once \n"
     ]
    }
   ],
   "source": [
    "text = 'Good mo'\n",
    "for i in range(200): text += get_next(text[-8:])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking a bit better but still not that great. Next step - replacing the for loop with a PyTorch component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharRnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will do exactly the same thing as the model above, the difference being that it no longer relies on the manual for loop. We will replace it with a nn.RNN layer.\n",
    "\n",
    "This is what that layer does (taken from [PyTorch documentation](http://pytorch.org/docs/master/nn.html#recurrent-layers)):\n",
    "\n",
    "$$h_t = \\tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "#         self.l_in = nn.Linear(n_fac, n_hidden) <- nn.RNN will do this for us already so this can go\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h0 = V(torch.zeros(1, bs, n_hidden).cuda())\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        \n",
    "        # output.shape = [8, bs, n_hidden]\n",
    "        # hn.shape = [1, bs, n_hidden]\n",
    "        #   turns out hn is the 'tensor containing the hidden state for k=seq_len' but for just a plain nn.RNN\n",
    "        #   that ends up being output[-1, bs, n_hidden] which can be quite confusing!\n",
    "        output, hn = self.rnn(inp, h0)\n",
    "        return F.log_softmax(self.l_out(output[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRNN(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1b472c71c340acacd354a58e2e3b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.83428  6.31489]                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a605cb53933b426298a9dbe23dd3ff32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.5256   5.58316]                                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 1, opt, F.nll_loss)\n",
    "set_lrs(opt, 1e-3)\n",
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Good mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good more States. Agen that be -adentind taxned our should is a coaligy. But surderfulloustand sume. You child. And so doebrets is wen's captory. And shory been mar ca supelesses fromightment intent terredia\n"
     ]
    }
   ],
   "source": [
    "text = 'Good mo'\n",
    "for i in range(200): text += get_next(text[-8:])\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on here? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did some copying of code from Jeremy's notebook. Things seem to work. I am starting to use nn.RNN which hides some of the complexity (and I think I understand what it does).\n",
    "\n",
    "But something feels a bit off. Would I be able to create a model from scratch?\n",
    "\n",
    "At this point, all this seems quite fuzzy. The only way to really learn this is to build a model from scratch myself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a string of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will build a very simple RNN for evaluating a simple calculation contained in a string, for example '2+3'. For this example, the network should output the number 5.\n",
    "\n",
    "I understand that this will be doing very little, but that is the plan. There are so many ways that this could be extended. Including other types of calculations, summing up digits in a string up until some special character indicating going back to zero (for testing forget gates), etc.\n",
    "\n",
    "Let's see if I can get the most basic of models to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "summands = [[x1, x2] for x1 in range(10) for x2 in range(10)]\n",
    "\n",
    "y = map(lambda lst: lst[0] + lst[1], summands)\n",
    "y = np.stack(y).reshape((-1,1))\n",
    "\n",
    "xs = map(lambda lst: [str(lst[0]), '+', str(lst[1])], summands)\n",
    "xs = np.stack(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 7],\n",
       "       [ 5],\n",
       "       [12],\n",
       "       [10],\n",
       "       [ 8],\n",
       "       [15]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[::16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '+', '0'],\n",
       "       ['1', '+', '6'],\n",
       "       ['3', '+', '2'],\n",
       "       ['4', '+', '8'],\n",
       "       ['6', '+', '4'],\n",
       "       ['8', '+', '0'],\n",
       "       ['9', '+', '6']],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[::16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = np.unique(xs)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 11\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to easily go from char to its index in the vocabulary and back. Let's use dictionaries for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {c: idx for idx, c in enumerate(chars)}\n",
    "idx2char = {idx: c for idx, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert our xs to an array with indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx_ufunc = np.vectorize(lambda c: char2idx[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idxs = char2idx_ufunc(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  1],\n",
       "       [ 2,  0,  7],\n",
       "       [ 4,  0,  3],\n",
       "       [ 5,  0,  9],\n",
       "       [ 7,  0,  5],\n",
       "       [ 9,  0,  1],\n",
       "       [10,  0,  7]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_idxs[::16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to rock :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both xs and y are ordered - this sort of selection of the val set will lead to the model never seeing '9' as x1\n",
    "md = ColumnarModelData.from_arrays('.', [-10], x_idxs, y.astype(np.float32), bs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental model construction.\n",
    "\n",
    "Will not go into my next post as it would make the code too messy. Wanted to share as I find it very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        \n",
    "        # many simplifications here, which is good -\n",
    "        #   I'll make the model only as complex as it needs to be to learn\n",
    "        self.n_hidden = n_fac\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_hidden = nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.l_out = nn.Linear(self.n_hidden, 1)\n",
    "    \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, self.n_hidden).cuda())\n",
    "        \n",
    "        for c in cs:\n",
    "            inp = self.e(c)\n",
    "            h = inp + self.l_hidden(h)\n",
    "        \n",
    "        return self.l_out(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Calculator(vocab_size, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25724cee295143909d3f3e6e577ea28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       81.94344   3.13505]                  \n",
      "[  1.       44.22871   1.96429]                  \n",
      "[  2.       28.90028   3.84676]                  \n",
      "[  3.       18.40855   9.18894]                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3c53ded1cc472e8b1f156e06c93efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       1.64152  6.71108]                     \n",
      "[ 1.       1.46116  4.95674]                     \n",
      "[ 2.       1.27369  3.99521]                     \n",
      "[ 3.       1.08349  2.33228]                     \n",
      "[ 4.       0.91851  1.82099]                      \n",
      "[ 5.       0.76727  1.46149]                      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1)\n",
    "\n",
    "fit(m, md, 4, opt, F.mse_loss)\n",
    "set_lrs(opt, 1e-1)\n",
    "fit(m, md, 6, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NN has very few parameters so it is quite susceptible to local minima. You might have to restart the training a couple of times to get nice results as above.\n",
    "\n",
    "Now the fun thing! What has our NN learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-3.9842\n",
       " 2.4200\n",
       " 2.3855\n",
       " 0.9966\n",
       "-1.4621\n",
       "-2.4677\n",
       "-3.6912\n",
       "-4.8159\n",
       "-4.8263\n",
       "-6.6776\n",
       "-9.0398\n",
       "[torch.cuda.FloatTensor of size 11x1 (GPU 0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.e.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-1.0264\n",
       "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.l_hidden.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-0.7582\n",
       "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.l_out.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network can converge to various solutions - with the hidden weight being a very small number close to zero, or one close to +1 or -1, etc. You might want to rerun the training and see what happens!\n",
    "\n",
    "I tried adding a tanh activation between the hidden states but it didn't work. Makes sense if you think about what the network is doing. \n",
    "\n",
    "Can we get this to work with a hidden state and a tanh nonlinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorWithNonlinearities(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden) # we need this because now n_fac != n_hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, 1)\n",
    "    \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, self.n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = self.l_in(self.e(c))\n",
    "            h = F.tanh(self.l_hidden(h + inp))\n",
    "        return self.l_out(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that 1 should work for the n_fac - the NN just needs to learn the number corresponding to each char. But what about n_hidden?\n",
    "\n",
    "How small can I make the network for it to learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CalculatorWithNonlinearities(vocab_size, 1, 20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10ea380395748d9bc3a8f6d848af7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       66.14835  21.62745]                  \n",
      "[  1.       42.2609    1.72222]                  \n",
      "[  2.       30.39179   0.08944]                  \n",
      "[  3.       24.26544   0.03263]                  \n",
      "[  4.       21.06459   0.14275]                  \n",
      "[  5.       18.88719   0.03486]                  \n",
      "[  6.       16.91121   0.06657]                  \n",
      "[  7.       14.98446   1.69308]                  \n",
      "[  8.       13.17066   0.76843]                  \n",
      "[  9.       11.54898   7.11219]                  \n",
      "[ 10.       10.06652   3.6616 ]                  \n",
      "[ 11.        8.28587   4.35489]                  \n",
      "[ 12.        6.70898   3.56428]                  \n",
      "[ 13.        5.34851   2.9674 ]                  \n",
      "[ 14.        4.13392   2.51921]                  \n",
      "[ 15.        3.08958   0.42672]                  \n",
      "[ 16.        2.29914   0.30198]                  \n",
      "[ 17.        1.65553   0.3035 ]                  \n",
      "[ 18.        1.1885    0.52241]                  \n",
      "[ 19.        0.86083   0.49692]                   \n",
      "[ 20.        0.62775   0.38306]                   \n",
      "[ 21.        0.46565   0.397  ]                   \n",
      "[ 22.        0.34513   0.22854]                   \n",
      "[ 23.        0.26016   0.28301]                   \n",
      "[ 24.        0.20058   0.33192]                   \n",
      "[ 25.        0.15833   0.09544]                   \n",
      "[ 26.        0.12441   0.18748]                             \n",
      "[ 27.        0.09867   0.14642]                    \n",
      "[ 28.        0.08055   0.09019]                    \n",
      "[ 29.        0.06904   0.1892 ]                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 30, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what it's worth, 10 dimensionsional hidden state seems to be too small for this method of training / architecture. 20 seems to do the trick.\n",
    "\n",
    "Let's see what embeddings it learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.7059\n",
       " 1.4007\n",
       " 1.1018\n",
       " 0.8484\n",
       " 0.6089\n",
       " 0.3554\n",
       " 0.1097\n",
       "-0.1371\n",
       "-0.3852\n",
       "-0.6220\n",
       "-0.9086\n",
       "[torch.cuda.FloatTensor of size 11x1 (GPU 0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.e.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense! Now time for getting it to work with the nn.RNN black box.\n",
    "\n",
    "Pasting the equation summarizing what it does here so that I know what to feed it and what I can expect to come out of it:\n",
    "$$h_t = \\tanh(w_{ih} * x_t + b_{ih}  +  w_{hh} * h_{(t-1)} + b_{hh})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorWithRNNCell(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)   \n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, 1)\n",
    "    \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        h0 = V(torch.zeros(1, bs, self.n_hidden).cuda())\n",
    "        out, _ = self.rnn(inp, h0)\n",
    "        \n",
    "        return self.l_out(out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CalculatorWithRNNCell(vocab_size, 1, 20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3ebf38e0714120a3b9d8db15eed200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.       49.11596   9.42365]                            \n",
      "[  1.       31.13147   0.05916]                            \n",
      "[  2.       24.25076   0.14015]                            \n",
      "[  3.       21.08268   0.01221]                            \n",
      "[  4.       19.50281   0.04864]                            \n",
      "[  5.       18.45021   0.00196]                            \n",
      "[  6.       17.89862   0.00804]                            \n",
      "[  7.       17.73083   0.02894]                            \n",
      "[  8.       17.52084   0.05901]                            \n",
      "[  9.       17.16917   0.00533]                            \n",
      "[ 10.       16.74032   0.0291 ]                            \n",
      "[ 11.       16.58917   0.74846]                  \n",
      "[ 12.       16.12264   1.24357]                            \n",
      "[ 13.       15.27243  11.13585]                            \n",
      "[ 14.       14.131     1.42411]                            \n",
      "[ 15.       11.71144   1.18931]                            \n",
      "[ 16.        8.90745   2.72275]                            \n",
      "[ 17.        6.52218   7.53697]                            \n",
      "[ 18.        4.66879   5.34479]                            \n",
      "[ 19.        3.35832   3.05731]                            \n",
      "[ 20.        2.40867   2.76123]                            \n",
      "[ 21.        1.73517   1.71748]                            \n",
      "[ 22.        1.25789   1.31269]                            \n",
      "[ 23.        0.92274   1.3178 ]                             \n",
      "[ 24.        0.68112   0.93627]                             \n",
      "[ 25.        0.5186    0.93557]                             \n",
      "[ 26.        0.39998   0.79343]                             \n",
      "[ 27.        0.30642   0.70719]                             \n",
      "[ 28.        0.23828   0.54667]                             \n",
      "[ 29.        0.19237   0.48117]                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)\n",
    "\n",
    "fit(m, md, 30, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['+', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-1.1853\n",
       " 2.2100\n",
       " 1.2919\n",
       " 0.8742\n",
       " 0.5553\n",
       " 0.2421\n",
       "-0.1066\n",
       "-0.4738\n",
       "-0.8615\n",
       "-1.4669\n",
       "-2.3471\n",
       "[torch.cuda.FloatTensor of size 11x1 (GPU 0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.e.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for part 1! In part 2 we will look at longer sequences and specifically the LTSM and GRU cells! \n",
    "\n",
    "See you in part 2!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun things to try\n",
    "\n",
    "* The RNNs for the learning from speeches part have not been tuned. Can you lower the validation loss by picking different embedding / hidden state dimensions? What about learning rate annealing (decreasing the learning rate as you train) or adding batch norm / dropout?\n",
    "* Can you teach the network to perform other calculations, such as subtraction or multiplication? How big of a hidden state do you need to make it work?\n",
    "* What about a network that would take in long sequences of ones and zeros and count the ones? How long can we make such a sequence before the network is unable to learn?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
